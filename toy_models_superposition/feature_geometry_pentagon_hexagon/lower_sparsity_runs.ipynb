{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import random\n",
    "import torch as t\n",
    "from torch import nn, Tensor\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Float, Int\n",
    "from typing import Optional, Callable, Union, List, Tuple\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "# from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import copy\n",
    "import shap\n",
    "import plotly.express as px\n",
    "\n",
    "chapter = \"chapter1_transformer_interp\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "section_dir = (exercises_dir / \"part4_superposition_and_saes\").resolve()\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from plotly_utils import imshow, line, hist\n",
    "from part31_superposition_and_saes.utils import (\n",
    "    plot_features_in_2d,\n",
    "    plot_features_in_Nd,\n",
    "    plot_features_in_Nd_discrete,\n",
    "    plot_correlated_features,\n",
    "    plot_feature_geometry,\n",
    "    frac_active_line_plot,\n",
    "    animate_features_in_2d\n",
    ")\n",
    "\n",
    "from feature_geometry_utils import *\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not t.backends.mps.is_available():\n",
    "    if not t.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = t.device(\"mps\")\n",
    "\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower Sparsity Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_probability(n_instances):\n",
    "    feature_prob = (1000 ** -t.linspace(0, 1, n_instances))\n",
    "    feature_prob = einops.rearrange(feature_prob, \"instances -> instances ()\")\n",
    "    return feature_prob\n",
    "\n",
    "def feature_importance(n_features):\n",
    "    importance = (0.9 ** t.arange(n_features))\n",
    "    importance = einops.rearrange(importance, \"features -> () features\")\n",
    "    return importance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_probability(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_metadata(n_features, n_instances = 8,optim_fn=t.optim.Adam):\n",
    "    print(f\"n_features:{n_features}\")\n",
    "\n",
    "    cfg = Config(\n",
    "            n_instances = n_instances,\n",
    "            n_features = n_features,\n",
    "            n_hidden = 2,\n",
    "            optim_fn = optim_fn\n",
    "        )\n",
    "\n",
    "    \n",
    "    # importance varies within features for each instance\n",
    "    importance = feature_importance(cfg.n_features)\n",
    "    \n",
    "    # sparsity is the same for all features in a given instance, but varies over instances\n",
    "    feature_prob = feature_probability(cfg.n_instances)\n",
    "\n",
    "    model = Model(\n",
    "        cfg = cfg,\n",
    "        device = device,\n",
    "        importance = importance,\n",
    "        feature_probability = feature_prob,\n",
    "    )\n",
    "    summed_losses, losses, batches,all_W, all_b, per_feature_losses = model.optimize(steps=10_000)\n",
    "\n",
    "    results_dict = {}\n",
    "    results_dict[\"n_features\"] = n_features\n",
    "    results_dict[\"model\"] = model\n",
    "    results_dict[\"importance\"] = model.importance\n",
    "    results_dict[\"feature_prob\"] = feature_prob\n",
    "    results_dict[\"W\"] = model.W.detach()\n",
    "    results_dict[\"b\"] = model.b_final.detach()\n",
    "    results_dict[\"summed_loss\"] = summed_losses\n",
    "    results_dict[\"per_feature_losses\"] = per_feature_losses\n",
    "    results_dict[\"losses\"] = losses\n",
    "    results_dict[\"batches\"] = batches\n",
    "    results_dict[\"all_W\"] = all_W\n",
    "    results_dict[\"all_b\"] = all_b\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_list = list(range(4,11))\n",
    "results_list = []\n",
    "\n",
    "for n_feature in n_features_list:\n",
    "    results_list.append(save_experiment_metadata(n_feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting per feature norms with total norm and total loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg_window = 20\n",
    "for result in results_list:\n",
    "    print(\"n_feature:\", result['n_features'])\n",
    "    feature_wise_norm_lowest_sparsity = [t.norm(t.tensor(W[-1]),dim=0).cpu().tolist() for W in result['all_W']]\n",
    "    lowest_sparsity_norm = [t.norm(t.tensor(W[-1])).item() for W in result['all_W']]\n",
    "    lowest_sparsity_loss = pd.DataFrame(result['losses'])[7].values\n",
    "    n_features_learned = [sum(np.round(np.abs(W[-1]).sum(axis = 0),0)>0).item() for W in result['all_W']]\n",
    "    df = pd.DataFrame(feature_wise_norm_lowest_sparsity)\n",
    "    df['norm'] = lowest_sparsity_norm\n",
    "    df['loss'] = lowest_sparsity_loss\n",
    "    df['n_features_learned'] = n_features_learned\n",
    "    moving_avg_loss = df['loss'].rolling(window=moving_avg_window).mean()\n",
    "   \n",
    "    \n",
    "    fig = df.plot()\n",
    "    \n",
    "    # Add the second trace for y2\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df.index[moving_avg_window-1:], y=df['n_features_learned'].iloc[moving_avg_window-1:], name='n_features_learned', yaxis='y2')\n",
    "    )\n",
    "    \n",
    "    # Update layout for dual axes\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(title='norm/n_features_learned', side='left'),\n",
    "        yaxis2=dict(title='loss', overlaying='y', side='right'),\n",
    "        xaxis=dict(title='x'),\n",
    "        title='Dual Axis Plot with Plotly'\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animation for n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tensor(results_list[0]['all_W'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_w = [t.tensor(W) for W in results_list[3]['all_W']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_w[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_features_in_2d(\n",
    "    {\n",
    "        \"weights\": t.stack(all_w),\n",
    "    },\n",
    "    steps=df.index[moving_avg_window-1:].tolist(),\n",
    "    filename=\"animation-n_features_7.html\",\n",
    "    title=\"Visualizing 7 features across epochs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_df = pd.DataFrame()\n",
    "for optim_fn, results in zip(optim_fn_list,optim_results_list):\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "    print(\"optim_fn:\",optim_fn)\n",
    "    optim_df[f\"{optim_fn.__name__}\"] = pd.DataFrame(results['losses'])[7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[result['n_features'] for result in results_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.norm(results_list[3]['W'][-2]),t.norm(results_list[3]['W'][-2],dim=0),results_list[3]['W'][-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.norm(results_list[3]['W'][-2],dim=0).cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in results_list:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "        annotations= True\n",
    "    )\n",
    "    corr_plots(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['importance'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['W'][0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_plots(results, instances=8):\n",
    "    fig, ax = plt.subplots(1, instances, figsize=(25, 4))\n",
    "\n",
    "    ax[0].set_ylabel(\"feature correlation\")\n",
    "    for i in range(instances):\n",
    "        W = results['W'][i].T.cpu()\n",
    "        corr = t.corrcoef(W).cpu().numpy()\n",
    "        ax[i].set_title(f\"Sparsity: {np.round(results['feature_prob'][i].item(),3)}\")\n",
    "        ax[i].imshow(corr,cmap='viridis',aspect='equal')\n",
    "        \n",
    "        ax[i].set_xticks(np.arange(0, corr.shape[0], 1))\n",
    "        ax[i].set_yticks(np.arange(0, corr.shape[0], 1))\n",
    "        ax[i].set_xticklabels(np.arange(0, corr.shape[0], 1))\n",
    "        ax[i].set_yticklabels(np.arange(0, corr.shape[0], 1))\n",
    "        ax[i].set_xticks(np.arange(-.5, corr.shape[0], 1), minor=True)\n",
    "        ax[i].set_yticks(np.arange(-.5, corr.shape[0], 1), minor=True)\n",
    "        ax[i].grid(which='minor', color='w', linestyle='-', linewidth=2)\n",
    "\n",
    "    im = ax[i].imshow(corr,cmap='viridis',aspect='equal')    \n",
    "    fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.05, pad=0.04)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_plots(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising hidden layers for the last batch of inputs\n",
    "for results in results_list:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    hidden = einops.einsum(results['batches'][-1].to(device), results['W'], \"... instances features, instances n_hidden features -> ... instances n_hidden\")\n",
    "\n",
    "    hidden = einops.rearrange(hidden, \"batch instances hidden -> instances hidden batch\")\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        hidden,\n",
    "        colors = \"red\",\n",
    "        title = f\"Hidden Layer: Input of {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_6 = []\n",
    "\n",
    "for n in range(5):\n",
    "    results_list_6.append(save_experiment_metadata(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in results_list[7:]:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_probability(n_instances):\n",
    "    feature_prob = (1500 ** -t.linspace(0, 1, n_instances))\n",
    "    feature_prob = einops.rearrange(feature_prob, \"instances -> instances ()\")\n",
    "    return feature_prob\n",
    "\n",
    "def feature_importance(n_features):\n",
    "    importance = (0.7 ** t.arange(n_features))\n",
    "    importance = einops.rearrange(importance, \"features -> () features\")\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_probability(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_6 = []\n",
    "\n",
    "for n in range(5):\n",
    "    results_list_6.append(save_experiment_metadata(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in results_list_6:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Lower Sparsity runs for all n_feature with RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_probability(n_instances):\n",
    "    feature_prob = (1500 ** -t.linspace(0, 1, n_instances))\n",
    "    feature_prob = einops.rearrange(feature_prob, \"instances -> instances ()\")\n",
    "    return feature_prob\n",
    "\n",
    "def feature_importance(n_features):\n",
    "    importance = (0.7 ** t.arange(n_features))\n",
    "    importance = einops.rearrange(importance, \"features -> () features\")\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_probability(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_list = list(range(4,11))\n",
    "rmsprop_low_sparsity_results_list = []\n",
    "\n",
    "for n_feature in n_features_list:\n",
    "    rmsprop_low_sparsity_results_list.append(save_experiment_metadata(n_feature,8,t.optim.RMSprop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in rmsprop_low_sparsity_results_list:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "    )\n",
    "    corr_plots(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Lower Sparsity runs for n_feature=6 with RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop_low_sparsity_results_list_6 = []\n",
    "\n",
    "for n in range(5):\n",
    "    rmsprop_low_sparsity_results_list_6.append(save_experiment_metadata(6,10,t.optim.RMSprop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in rmsprop_low_sparsity_results_list_6:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "    )\n",
    "    corr_plots(results,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Hexagon Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_probability(n_instances):\n",
    "    feature_prob = (25 ** -t.linspace(0, 1, n_instances))\n",
    "    feature_prob = einops.rearrange(feature_prob, \"instances -> instances ()\")\n",
    "    return feature_prob\n",
    "\n",
    "def feature_importance(n_features):\n",
    "    importance = (1 ** t.arange(n_features))\n",
    "    importance = einops.rearrange(importance, \"features -> () features\")\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_probability(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list_hexagon_replication = []\n",
    "\n",
    "for n in range(10):\n",
    "    results_list_hexagon_replication.append(save_experiment_metadata(6,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in results_list_hexagon_replication:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initialization Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_batch_6_fixed_init = []\n",
    "\n",
    "n_features=6\n",
    "n_instances=8\n",
    "optim_fn=t.optim.Adam\n",
    "\n",
    "cfg = Config(\n",
    "        n_instances = n_instances,\n",
    "        n_features = n_features,\n",
    "        n_hidden = 2,\n",
    "        optim_fn = optim_fn\n",
    "    )\n",
    "\n",
    "\n",
    "# importance varies within features for each instance\n",
    "importance = feature_importance(cfg.n_features)\n",
    "\n",
    "# sparsity is the same for all features in a given instance, but varies over instances\n",
    "feature_prob = feature_probability(cfg.n_instances)\n",
    "\n",
    "model = Model(\n",
    "    cfg = cfg,\n",
    "    device = device,\n",
    "    importance = importance,\n",
    "    feature_probability = feature_prob,\n",
    ")\n",
    "\n",
    "for n in range(5):\n",
    "\n",
    "    new_model = copy.deepcopy(model)\n",
    "    summed_losses, losses, batches = new_model.optimize(steps=10_000)\n",
    "\n",
    "    results_dict = {}\n",
    "    results_dict[\"n_features\"] = n_features\n",
    "    results_dict[\"importance\"] = new_model.importance\n",
    "    results_dict[\"feature_prob\"] = feature_prob\n",
    "    results_dict[\"W\"] = new_model.W.detach()\n",
    "    results_dict[\"b\"] = new_model.b_final.detach()\n",
    "    results_dict[\"summed_loss\"] = summed_losses\n",
    "    results_dict[\"losses\"] = losses\n",
    "    results_dict[\"batches\"] = batches\n",
    "    random_batch_6_fixed_init.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results in random_batch_6_fixed_init:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob'].squeeze()],\n",
    "        annotations = True\n",
    "    )\n",
    "    corr_plots(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "2bf1b3ab3bf4993279d6e4d507e32e29da12e88795dbb4a207694a5b99d95980"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
