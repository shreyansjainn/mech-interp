{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f81fb4-5f99-4c51-9a62-096579b579a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import random\n",
    "import torch as t\n",
    "from torch import nn, Tensor\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import einops\n",
    "from jaxtyping import Float, Int\n",
    "from typing import Optional, Callable, Union, List, Tuple\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "# from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import copy\n",
    "import shap\n",
    "import plotly.express as px\n",
    "\n",
    "chapter = \"chapter1_transformer_interp\"\n",
    "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
    "section_dir = (exercises_dir / \"part4_superposition_and_saes\").resolve()\n",
    "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
    "\n",
    "from plotly_utils import imshow, line, hist\n",
    "from part31_superposition_and_saes.utils import (\n",
    "    plot_features_in_2d,\n",
    "    plot_features_in_Nd,\n",
    "    plot_features_in_Nd_discrete,\n",
    "    plot_correlated_features,\n",
    "    plot_feature_geometry,\n",
    "    frac_active_line_plot,\n",
    "    animate_features_in_2d\n",
    ")\n",
    "\n",
    "from feature_geometry_utils import *\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not t.backends.mps.is_available():\n",
    "    if not t.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    device = t.device(\"mps\")\n",
    "\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab0134-ba8d-4c06-9d06-de651aa1e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(n_features):\n",
    "    importance = (1 ** t.arange(n_features))\n",
    "    importance = einops.rearrange(importance, \"features -> () features\")\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4be73-5550-42fa-ad77-b7358853e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02da10f-6283-46be-a8e5-c84dde886a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_metadata(n_features,seed, feature_prob ,n_instances = 1,optim_fn=t.optim.Adam):\n",
    "    print(f\"n_features:{n_features}\")\n",
    "    print(f\"seed:{seed}\")\n",
    "\n",
    "    t.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    cfg = Config(\n",
    "            n_instances = n_instances,\n",
    "            n_features = n_features,\n",
    "            n_hidden = 2,\n",
    "            optim_fn = optim_fn\n",
    "        )\n",
    "\n",
    "    \n",
    "    # importance varies within features for each instance\n",
    "    importance = feature_importance(cfg.n_features)\n",
    "    \n",
    "    # # sparsity is the same for all features in a given instance, but varies over instances\n",
    "    # feature_prob = feature_probability(cfg.n_instances)\n",
    "\n",
    "    model = Model(\n",
    "        cfg = cfg,\n",
    "        device = device,\n",
    "        importance = importance,\n",
    "        feature_probability = feature_prob,\n",
    "    )\n",
    "    output_dict = model.optimize(steps=10_000)\n",
    "\n",
    "    results_dict = {}\n",
    "    results_dict[\"n_features\"] = n_features\n",
    "    results_dict[\"seed\"] = seed\n",
    "    results_dict[\"model\"] = model\n",
    "    results_dict[\"importance\"] = model.importance\n",
    "    results_dict[\"feature_prob\"] = feature_prob\n",
    "    results_dict[\"W\"] = model.W.detach()\n",
    "    results_dict[\"b\"] = model.b_final.detach()\n",
    "    results_dict[\"output_dict\"] = output_dict\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c49e3-8d7b-4174-b87a-a7ff78249f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_vs_feature_learned(result, index):\n",
    "    print(\"n_feature:\", result['n_features'])\n",
    "    feature_wise_norm = [t.norm(W[index],dim=0).cpu().tolist() for W in result['output_dict']['all_W']]\n",
    "    overall_norm = [t.norm(W[index]).item() for W in result['output_dict']['all_W']]\n",
    "    n_features_learned = [sum(np.round(np.abs(W[index]).sum(axis = 0),0)>0).item() for W in result['output_dict']['all_W']]\n",
    "    df = pd.DataFrame(feature_wise_norm)\n",
    "    df['overall_norm'] = overall_norm\n",
    "    \n",
    "    fig = df.plot()\n",
    "        \n",
    "    # Add the second trace for y2\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df.index, y=n_features_learned, name='n_features_learned', yaxis='y2')\n",
    "    )\n",
    "    \n",
    "    # Update layout for dual axes\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(title='norm/n_features_learned', side='left'),\n",
    "        yaxis2=dict(title='loss', overlaying='y', side='right'),\n",
    "        xaxis=dict(title='x'),\n",
    "        title='Dual Axis Plot with Plotly'\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "def per_feature_loss_viz(result, index, test_loss=False, log=False,moving_avg_window = 20):\n",
    "    print(\"n_feature:\", result['n_features'])\n",
    "    if not test_loss:\n",
    "        per_feature_loss_key = 'per_feature_losses'\n",
    "        loss_key = 'losses'\n",
    "        title='Per Feature loss vs overall loss'\n",
    "    else:\n",
    "        per_feature_loss_key = 'test_per_feature_losses'\n",
    "        loss_key = 'test_losses'\n",
    "        title = \"Test Per Feature loss vs test overall loss\"\n",
    "        \n",
    "    per_feature_loss_df = pd.DataFrame([per_feature_loss[index] for per_feature_loss in result['output_dict'][per_feature_loss_key]])\n",
    "    per_feature_loss_df['overall_loss'] = pd.DataFrame(result['output_dict'][loss_key])[index].values\n",
    "    n_features_learned = [sum(np.round(np.abs(W[index]).sum(axis = 0),0)>0).item() for W in result['output_dict']['all_W']]\n",
    "\n",
    "    moving_avg_loss = per_feature_loss_df.rolling(window=moving_avg_window).mean()\n",
    "    \n",
    "    if not log:\n",
    "        fig = moving_avg_loss.iloc[moving_avg_window-1:].plot()    \n",
    "    else:\n",
    "        fig = np.log(moving_avg_loss.iloc[moving_avg_window-1:]).plot()\n",
    "        \n",
    "    # Add the second trace for y2\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=moving_avg_loss.index[moving_avg_window-1:], y=n_features_learned[moving_avg_window-1:], name='n_features_learned', yaxis='y2')\n",
    "    )\n",
    "    \n",
    "    # Update layout for dual axes\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(title='per_feature_loss/overall loss', side='left'),\n",
    "        yaxis2=dict(title='n_features_learned', overlaying='y', side='right'),\n",
    "        xaxis=dict(title='x'),\n",
    "        title=title\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280664a7-4e7e-4ae9-841b-5e165eadb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "seed = 20\n",
    "hexagon_result_057_20 = save_experiment_metadata(n_features = 7,seed = seed,feature_prob=feature_prob,n_instances=1)\n",
    "\n",
    "print(\"n_features:\",hexagon_result_057_20['n_features'])\n",
    "\n",
    "plot_features_in_2d(\n",
    "    hexagon_result_057_20['W'],\n",
    "    colors = hexagon_result_057_20['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_057_20['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_057_20['feature_prob']],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250907f-5ec1-4be2-bcac-abea2a038d8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b256b-f239-4caf-86f9-50cc977d09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "seed = 20\n",
    "hexagon_result_057_20 = save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1)\n",
    "\n",
    "print(\"n_features:\",hexagon_result_057_20['n_features'])\n",
    "\n",
    "plot_features_in_2d(\n",
    "    hexagon_result_057_20['W'],\n",
    "    colors = hexagon_result_057_20['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_057_20['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_057_20['feature_prob']],\n",
    ")\n",
    "\n",
    "norm_vs_feature_learned(hexagon_result_057_20,0)\n",
    "\n",
    "per_feature_loss_viz(hexagon_result_057_20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b672207-58b5-4c12-9120-70044fccc212",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grad_norm_057_20 = [t.norm(W[0],dim=0).cpu().tolist() for W in hexagon_result_057_20['output_dict']['all_W_grad']]\n",
    "grad_norm_057_20_df = pd.DataFrame(feature_grad_norm_057_20)\n",
    "moving_grad_norm_057_20_df = grad_norm_057_20_df.rolling(window=moving_avg_window).mean()\n",
    "moving_grad_norm_057_20_df.iloc[moving_avg_window-1:].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9b49a-4284-421a-b4fd-2477ba05f3e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2039bf-464d-40c3-8a56-9e3037409884",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "seed = 26\n",
    "hexagon_result_057_26 = save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1)\n",
    "\n",
    "print(\"n_features:\",hexagon_result_057_26['n_features'])\n",
    "\n",
    "plot_features_in_2d(\n",
    "    hexagon_result_057_26['W'],\n",
    "    colors = hexagon_result_057_26['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_057_26['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_057_26['feature_prob']],\n",
    ")\n",
    "\n",
    "norm_vs_feature_learned(hexagon_result_057_26,0)\n",
    "\n",
    "per_feature_loss_viz(hexagon_result_057_26, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce250fa-e835-4d22-8359-c7c0f62b55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.040])\n",
    "seed = 26\n",
    "hexagon_result_040_26 = save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1)\n",
    "\n",
    "print(\"n_features:\",hexagon_result_040_26['n_features'])\n",
    "\n",
    "plot_features_in_2d(\n",
    "    hexagon_result_040_26['W'],\n",
    "    colors = hexagon_result_040_26['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_040_26['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_040_26['feature_prob']],\n",
    ")\n",
    "\n",
    "norm_vs_feature_learned(hexagon_result_040_26,0)\n",
    "\n",
    "per_feature_loss_viz(hexagon_result_040_26, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106db26-dd65-4e2a-b837-57ec2db2c908",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### All three losses compared.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770b8f6-21e4-46dd-b1ec-526ab0132ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_057_20 = [loss[0] for loss in hexagon_result_057_20[\"output_dict\"]['losses']]\n",
    "loss_057_26 = [loss[0] for loss in hexagon_result_057_26[\"output_dict\"]['losses']]\n",
    "loss_040_26 = [loss[0] for loss in hexagon_result_040_26[\"output_dict\"]['losses']]\n",
    "\n",
    "loss_df = pd.DataFrame({\"loss_057_20\":loss_057_20,\"loss_057_26\":loss_057_26,\"loss_040_26\":loss_040_26})\n",
    "\n",
    "moving_avg_window = 20\n",
    "moving_avg_loss = loss_df.rolling(window=moving_avg_window).mean()\n",
    "moving_avg_loss.iloc[moving_avg_window-1:].plot()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e7ab1-6371-4dc8-93eb-4dc4f7d2a4d2",
   "metadata": {},
   "source": [
    "### All three norms compared.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913148f-8eeb-4ba5-8574-1c540424f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_norm_057_20 = [t.norm(W).item() for W in hexagon_result_057_20[\"output_dict\"]['all_W']]\n",
    "overall_norm_057_26 = [t.norm(W).item() for W in hexagon_result_057_26[\"output_dict\"]['all_W']]\n",
    "overall_norm_040_26 = [t.norm(W).item() for W in hexagon_result_040_26[\"output_dict\"]['all_W']]\n",
    "\n",
    "pd.DataFrame({\"pentagon\":overall_norm_057_20,\"hexagon\":overall_norm_057_26}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d42e86-4d44-45a6-bdda-65b74c1861fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_norm_057_20[0],overall_norm_057_26[0],overall_norm_040_26[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9ff0fd-6046-4b72-9635-8541046844b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features_in_2d(\n",
    "    t.Tensor(hexagon_result_057_20[\"output_dict\"]['all_W'][0]),\n",
    "    colors = hexagon_result_057_20['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_057_20['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_057_20['feature_prob']],\n",
    ")\n",
    "\n",
    "plot_features_in_2d(\n",
    "    t.Tensor(hexagon_result_057_26[\"output_dict\"]['all_W'][0]),\n",
    "    colors = hexagon_result_057_26['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_057_26['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_057_26['feature_prob']],\n",
    ")\n",
    "\n",
    "plot_features_in_2d(\n",
    "    t.Tensor(hexagon_result_040_26[\"output_dict\"]['all_W'][0]),\n",
    "    colors = hexagon_result_040_26['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_040_26['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_040_26['feature_prob']],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9350ea82-b642-469d-8e00-4605431790e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### All three gradient norms compared.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9032ea7b-29a0-4f26-8bf8-4a3c2a230b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grad_norm_057_20 = [t.norm(W[0],dim=0).cpu().tolist() for W in hexagon_result_057_20['output_dict']['all_W_grad']]\n",
    "grad_norm_057_20_df = pd.DataFrame(feature_grad_norm_057_20)\n",
    "moving_grad_norm_057_20_df = grad_norm_057_20_df.rolling(window=moving_avg_window).mean()\n",
    "moving_grad_norm_057_20_df.iloc[moving_avg_window-1:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2191e5e-e261-439f-976f-43b4688ea581",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grad_norm_057_26 = [t.norm(W[0],dim=0).cpu().tolist() for W in hexagon_result_057_26['output_dict']['all_W_grad']]\n",
    "grad_norm_057_26_df = pd.DataFrame(feature_grad_norm_057_26)\n",
    "moving_grad_norm_057_26_df = grad_norm_057_26_df.rolling(window=moving_avg_window).mean()\n",
    "moving_grad_norm_057_26_df.iloc[moving_avg_window-1:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ae078c-c5ed-4710-a6b1-dc56eb8607df",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_grad_norm_040_26 = [t.norm(W[0],dim=0).cpu().tolist() for W in hexagon_result_040_26['output_dict']['all_W_grad']]\n",
    "grad_norm_040_26_df = pd.DataFrame(feature_grad_norm_040_26)\n",
    "moving_grad_norm_040_26_df = grad_norm_040_26_df.rolling(window=moving_avg_window).mean()\n",
    "moving_grad_norm_040_26_df.iloc[moving_avg_window-1:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7143f-3b69-4f45-91b9-ac1817ab7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_grad_norm_057_20 = [t.norm(W).item() for W in hexagon_result_057_20[\"output_dict\"]['all_W_grad']]\n",
    "overall_grad_norm_057_26 = [t.norm(W).item() for W in hexagon_result_057_26[\"output_dict\"]['all_W_grad']]\n",
    "overall_grad_norm_040_26 = [t.norm(W).item() for W in hexagon_result_040_26[\"output_dict\"]['all_W_grad']]\n",
    "\n",
    "grad_norm_df = pd.DataFrame({\"overall_grad_norm_057_20\":overall_grad_norm_057_20,\"overall_grad_norm_057_26\":overall_grad_norm_057_26,\"overall_grad_norm_040_26\":overall_grad_norm_040_26})\n",
    "\n",
    "moving_avg_window = 20\n",
    "moving_grad_norm = grad_norm_df.rolling(window=moving_avg_window).mean()\n",
    "moving_grad_norm.iloc[moving_avg_window-1:].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4f746-b509-4dda-865d-9367f1bfcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W.grad.detach().cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0b261-5d5f-4f4b-9f14-7fac7069f2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e92e82-9e38-42ad-9643-1476cd720a1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Inititalization Distribution Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718c0f5-54ee-49dc-9e1b-296360f69647",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.sqrt(2/8)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d871d7-2396-4d87-8e34-82350979ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccb3d4-82e2-4b4c-9902-b0ddd0e7904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "x = np.linspace(mu - 3*std, mu + 3*std, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, std))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f18ae-9de5-4ca9-bc30-a3f7d3696c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hexagon_result_040_26['all_W'][0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa31045-abd6-4468-87f1-58c84f5124f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hexagon_result_057_26['all_W'][0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714d223-12bf-4ba7-8c71-1b228af045ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hexagon_result_057_20['all_W'][0].flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d533b68-bfd5-4d4f-9a38-e9657219b5e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Animation for all three seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef1b09a-7af3-4c3f-bc0f-3c8784d3b88e",
   "metadata": {},
   "source": [
    "all_w = [W for W in hexagon_result_040_26['output_dict']['all_W']]\n",
    "animate_features_in_2d(\n",
    "    {\n",
    "        \"weights\": t.stack(all_w),\n",
    "    },\n",
    "    steps=len(all_w),\n",
    "    filename=\"hexagon_result_040_26.html\",\n",
    "    title=\"Visualizing 6 features across epochs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562e9cc-e19b-47de-9ebf-3e18528458ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a385b2-c0ed-488f-ae9e-c261ee961d74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Does hexagon replicates for all sparsities for a given seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c45c5b-d61e-4a5e-b435-e85f8173db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob_list = t.Tensor([0.057, 0.040, 0.03 ,0.02, 0.01, 0.001, 0.0001, 0.00001])\n",
    "seed = 26\n",
    "hexagon_result_diff_spars = []\n",
    "for feature_prob in feature_prob_list:\n",
    "    print(\"feature_prob:\", feature_prob)\n",
    "    hexagon_result_diff_spars.append(save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144b7a98-8a63-486c-a6c4-21eb07552151",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in hexagon_result_diff_spars:\n",
    "\n",
    "    print(\"feature_prob:\",result['feature_prob'])\n",
    "    plot_features_in_2d(\n",
    "        result['W'],\n",
    "        colors = result['importance'],\n",
    "        title = f\"Superposition: {result['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {result['feature_prob']:.3f}\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6251229-4dac-40cb-a077-f96104d423c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Does hexagon seeds have lower loss than pentagon seeds for a given sparsity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1c470-2248-48fd-b3e8-34eab47ce681",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "seed_list = [26, 94, 32, 715, 158, 50, 30,40, 60,70]\n",
    "result_diff_seeds = []\n",
    "for seed in seed_list:\n",
    "    print(\"seed:\", seed)\n",
    "    result_diff_seeds.append(save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614dca18-1e81-4bde-90e5-d52f207da6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in result_diff_seeds:\n",
    "\n",
    "    print(\"seed:\",result['seed'])\n",
    "    plot_features_in_2d(\n",
    "        result['W'],\n",
    "        colors = result['importance'],\n",
    "        title = f\"Superposition: {result['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_057_26['feature_prob']],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5e6d3-79be-4829-bccc-091b2214f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_dict = {}\n",
    "for result in result_diff_seeds:\n",
    "    losses_dict[result['seed']] = [entry[0] for entry in result['output_dict']['losses']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93de433-44a4-4725-b31e-b3b5820afe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg_window = 100\n",
    "losses_df = pd.DataFrame(losses_dict)\n",
    "losses_df.drop([158,50], axis = 1, inplace = True) # removing four feature seeds, as they were with very high loss and were distorting the plot\n",
    "losses_df.columns = [\"hex_26\", \"hex_94\", \"hex_32\", \"hex_715\", \"hex_30\", \"pent_40\", \"pent_60\", \"pen_70\"]\n",
    "color_dict = {\"hex_26\":'#565454',\"hex_94\":'#565454',\"hex_32\":'#565454',\"hex_715\":'#565454',\"hex_30\":'#565454',\"pent_40\":\"red\",\"pent_60\":\"red\",\"pen_70\":\"red\"}\n",
    "moving_avg_loss = losses_df.rolling(window=moving_avg_window).mean()\n",
    "moving_avg_loss.plot(x=losses_df.index, y = list(losses_df.columns), color_discrete_map = color_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0798d36-823e-424c-8b59-3a70e72fad60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Patching Hexagon seed to pentagon seed for the unlearnt feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3a06d-2a0f-48d4-bb69-6e16b31e6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pentagon_patching(n_features,feature_idx,pent_seed, hex_seed, feature_prob ,n_instances = 1,optim_fn=t.optim.Adam):\n",
    "\n",
    "    cfg = Config(\n",
    "            n_instances = n_instances,\n",
    "            n_features = n_features,\n",
    "            n_hidden = 2,\n",
    "            optim_fn = optim_fn\n",
    "        )\n",
    "    \n",
    "    # importance varies within features for each instance\n",
    "    importance = feature_importance(cfg.n_features)\n",
    "    \n",
    "    # # sparsity is the same for all features in a given instance, but varies over instances\n",
    "    # feature_prob = feature_probability(cfg.n_instances)\n",
    "    \n",
    "    print(f\"pent_seed:{pent_seed}\")\n",
    "    \n",
    "    t.manual_seed(pent_seed)\n",
    "    np.random.seed(pent_seed)\n",
    "    random.seed(pent_seed)\n",
    "    \n",
    "    pent_model = Model(\n",
    "        cfg = cfg,\n",
    "        device = device,\n",
    "        importance = importance,\n",
    "        feature_probability = feature_prob,\n",
    "    )\n",
    "    print(f\"hex_seed:{hex_seed}\")\n",
    "    t.manual_seed(hex_seed)\n",
    "    np.random.seed(hex_seed)\n",
    "    random.seed(hex_seed)\n",
    "    \n",
    "    hex_model = Model(\n",
    "        cfg = cfg,\n",
    "        device = device,\n",
    "        importance = importance,\n",
    "        feature_probability = feature_prob,\n",
    "    )\n",
    "\n",
    "    print(\"initial weight comparison\", pent_model.W == hex_model.W)\n",
    "\n",
    "    old_pent_w = pent_model.W.clone()\n",
    "\n",
    "    with t.no_grad():\n",
    "        pent_model.W[:,:,1] = hex_model.W[:,:,1]\n",
    "\n",
    "    print(\"later pent weight comparison \",pent_model.W == old_pent_w)\n",
    "    print(\"later hex and pent weight comparison\",pent_model.W == hex_model.W)\n",
    "\n",
    "    output_dict = pent_model.optimize(steps=10_000)\n",
    "    results_dict = {}\n",
    "    results_dict[\"n_features\"] = n_features\n",
    "    results_dict[\"seed\"] = seed\n",
    "    results_dict[\"model\"] = pent_model\n",
    "    results_dict[\"importance\"] = pent_model.importance\n",
    "    results_dict[\"feature_prob\"] = feature_prob\n",
    "    results_dict[\"W\"] = pent_model.W.detach()\n",
    "    results_dict[\"b\"] = pent_model.b_final.detach()\n",
    "    results_dict[\"output_dict\"] = output_dict\n",
    "\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b227d86-c561-4943-8996-bdcfcb1e1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "pent_seed = 20\n",
    "hex_seed=94\n",
    "feature_idx=1\n",
    "patched_pent_model_results_dict = pentagon_patching(n_features=6,feature_idx=feature_idx,pent_seed=pent_seed, hex_seed=hex_seed, feature_prob = feature_prob)\n",
    "\n",
    "plot_features_in_2d(\n",
    "    patched_pent_model_results_dict['W'],\n",
    "    colors = patched_pent_model_results_dict['importance'],\n",
    "    title = f\"Superposition: {patched_pent_model_results_dict['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in patched_pent_model_results_dict['feature_prob']],\n",
    ")\n",
    "\n",
    "norm_vs_feature_learned(patched_pent_model_results_dict,0)\n",
    "\n",
    "per_feature_loss_viz(patched_pent_model_results_dict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d3be9b-0f9a-4187-9917-934fcd015d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "pent_seed = 20\n",
    "hex_seed=32\n",
    "feature_idx=1\n",
    "patched_pent_model_results_dict = pentagon_patching(n_features=6,feature_idx=feature_idx,pent_seed=pent_seed, hex_seed=hex_seed, feature_prob = feature_prob)\n",
    "\n",
    "plot_features_in_2d(\n",
    "    patched_pent_model_results_dict['W'],\n",
    "    colors = patched_pent_model_results_dict['importance'],\n",
    "    title = f\"Superposition: {patched_pent_model_results_dict['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in patched_pent_model_results_dict['feature_prob']],\n",
    ")\n",
    "\n",
    "norm_vs_feature_learned(patched_pent_model_results_dict,0)\n",
    "\n",
    "per_feature_loss_viz(patched_pent_model_results_dict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c71fc57-65dd-4f53-81c9-9ca6f8963f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "pent_seed = 20\n",
    "hex_seed=30\n",
    "feature_idx=1\n",
    "patched_pent_model_results_dict = pentagon_patching(n_features=6,feature_idx=feature_idx,pent_seed=pent_seed, hex_seed=hex_seed, feature_prob = feature_prob)\n",
    "\n",
    "plot_features_in_2d(\n",
    "    patched_pent_model_results_dict['W'],\n",
    "    colors = patched_pent_model_results_dict['importance'],\n",
    "    title = f\"Superposition: {patched_pent_model_results_dict['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in patched_pent_model_results_dict['feature_prob']],\n",
    ")\n",
    "\n",
    "norm_vs_feature_learned(patched_pent_model_results_dict,0)\n",
    "\n",
    "per_feature_loss_viz(patched_pent_model_results_dict, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d759224-a433-49c3-8a8d-1b6172a10b6b",
   "metadata": {},
   "source": [
    "### Impact of optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568a939-f8db-4740-bf79-59df97efdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_fn_list = [t.optim.Adam, t.optim.AdamW, t.optim.SGD, t.optim.RMSprop]\n",
    "for optim_fn in optim_fn_list:\n",
    "    print(optim_fn)\n",
    "    diff_optim_runs(optim_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710ac19a-0dd2-4bca-ad73-bfcf36310e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "seed = 26\n",
    "optim_fn_list = [t.optim.Adam, t.optim.AdamW, t.optim.SGD, t.optim.RMSprop]\n",
    "diff_optim_results = []\n",
    "for optim_fn in optim_fn_list:\n",
    "    print(optim_fn)\n",
    "    diff_optim_results.append(save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1,optim_fn=optim_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba99232-8467-48e5-b449-94e4b760f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for optim_fn, result in zip(optim_fn_list,diff_optim_results):\n",
    "    \n",
    "    print(\"optim_fn:\",optim_fn)\n",
    "    \n",
    "    plot_features_in_2d(\n",
    "        result['W'],\n",
    "        colors = result['importance'],\n",
    "        title = f\"Superposition: {result['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in result['feature_prob']],\n",
    "    )\n",
    "    \n",
    "    norm_vs_feature_learned(result,0)\n",
    "    \n",
    "    per_feature_loss_viz(result, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492f140-05c0-46b0-80cd-a6ba2d785e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prob = t.Tensor([0.057])\n",
    "seed = 94\n",
    "hexagon_result_057_26 = save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1, optim_fn=t.optim.RMSprop)\n",
    "\n",
    "print(\"n_features:\",hexagon_result_057_26['n_features'])\n",
    "\n",
    "plot_features_in_2d(\n",
    "    hexagon_result_057_26['W'],\n",
    "    colors = hexagon_result_057_26['importance'],\n",
    "    title = f\"Superposition: {hexagon_result_057_26['n_features']} features represented in 2D space\",\n",
    "    subplot_titles = [f\"1 - S = {i:.3f}\" for i in hexagon_result_057_26['feature_prob']],\n",
    ")\n",
    "\n",
    "norm_vs_feature_learned(hexagon_result_057_26,0)\n",
    "\n",
    "per_feature_loss_viz(hexagon_result_057_26, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d52b4d-884c-446d-866b-705a42eaf380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ec0a6-b75f-45db-91ce-176bbd254f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9e90c-18d2-4f73-9bc1-732b80cadb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61f24267-73eb-4bbd-b3ba-b14600ecc65a",
   "metadata": {},
   "source": [
    "random_seed_list = random.sample(range(100, 1000), 10)\n",
    "print(random_seed_list)\n",
    "results_list_hexagon_replication = []\n",
    "\n",
    "for seed in random_seed_list:\n",
    "    feature_prob = t.Tensor([0.057])\n",
    "    results_list_hexagon_replication.append(save_experiment_metadata(n_features = 6,seed = seed,feature_prob=feature_prob,n_instances=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef529d36-fe9f-4afa-b5ff-8a65e16919dc",
   "metadata": {},
   "source": [
    "for results in results_list_hexagon_replication:\n",
    "    print(\"n_features:\",results['n_features'])\n",
    "    print(\"seed:\",results['seed'])\n",
    "\n",
    "    plot_features_in_2d(\n",
    "        results['W'],\n",
    "        colors = results['importance'],\n",
    "        title = f\"Superposition: {results['n_features']} features represented in 2D space\",\n",
    "        subplot_titles = [f\"1 - S = {i:.3f}\" for i in results['feature_prob']],\n",
    "    )\n",
    "\n",
    "    norm_vs_feature_learned(results,0)\n",
    "\n",
    "    per_feature_loss_viz(results, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafedd15-6136-4b4f-b11c-e56cef65d39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe24430-ebac-484d-948d-a537ae17332d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfaf59d-2a42-4df9-bbe0-2e30d4a3a5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
